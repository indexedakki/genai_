{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VvV4qImEwdg"
      },
      "source": [
        "Applying topic modelling and sentiment analysis techniques in order to extract text aspects and the sentiment expressed towards such aspects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5V-WlKWFuyv"
      },
      "source": [
        "### Medium Article - https://towardsdatascience.com/%EF%B8%8F-sentiment-analysis-aspect-based-opinion-mining-72a75e8c8a6d\r\n",
        "### Github repo -    https://github.com/LowriWilliams/Aspect_Sentiment_Analysis\r\n",
        "### Mobile reviews dataset - http://jmcauley.ucsd.edu/data/amazon/links.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ! pip install aspect-based-sentiment-analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VRM0U0aFDv8",
        "outputId": "fb91984a-ebf9-4455-ec62-6a226d593c61"
      },
      "source": [
        "! pip install vaderSentiment"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVZNfiHpCUp3",
        "outputId": "27787433-2f30-403a-f517-ffcf0c59da5f"
      },
      "source": [
        "! gdown --id 1qj87tve3snu_dUeSpcSpP1uIWzE0zqAg\r\n",
        "! gdown --id 1XWupY8IyOHKLvb6Qyd5Pn63_tlnzUYSB"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qj87tve3snu_dUeSpcSpP1uIWzE0zqAg\n",
            "To: /content/wn_affect.py\n",
            "100% 21.0k/21.0k [00:00<00:00, 35.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XWupY8IyOHKLvb6Qyd5Pn63_tlnzUYSB\n",
            "To: /content/stop_words_list.py\n",
            "100% 6.84k/6.84k [00:00<00:00, 9.73MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TEWJCl9ExC4"
      },
      "source": [
        "import json\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import sys\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords, sentiwordnet as swn\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk import ngrams\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.decomposition import LatentDirichletAllocation\r\n",
        "import collections\r\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\r\n",
        "from stop_words_list import stop_words_list\r\n",
        "from wn_affect import wn_affect \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuzCOM0eGXS7"
      },
      "source": [
        "## Data Preprocessing\r\n",
        "\r\n",
        "We’ll follow the standard set of pre-processing techniques used in several natural language processing tasks. Such techniques include:\r\n",
        "\r\n",
        "    Converting the text to lowercase.\r\n",
        "    Removing punctuation and additional white spaces.\r\n",
        "    Tokenisation.\r\n",
        "    Removing stop words.\r\n",
        "    Lemmatisation.\r\n",
        "\r\n",
        "Before we look into applying topic modelling techniques, the last pre-processing step is to vectorise the reviews, i.e. we need to represent the data into a numerical form so that the model can handle them. There are several representations you can use, with the popular methods being the word’s TF-IDF score or their frequency counts (bag-of-words approach). Here, we’ll stick to a bag-of-words representation. We’ll use the CounterVectorizer function from Sklearn’s feature extraction module. This function converts a collection of text to a matrix of word counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XnDzNykGLIt",
        "outputId": "3ccb69df-c238-4eca-d762-00d0122d80ca"
      },
      "source": [
        "### ! wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-08 14:21:12--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45409631 (43M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Cell_Phones_and_Accessories_5.json.gz’\n",
            "\n",
            "reviews_Cell_Phones 100%[===================>]  43.31M  6.04MB/s    in 8.4s    \n",
            "\n",
            "2021-02-08 14:21:21 (5.15 MB/s) - ‘reviews_Cell_Phones_and_Accessories_5.json.gz’ saved [45409631/45409631]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMUw6C8oEc73",
        "outputId": "d253149e-97ed-4fa5-9d2e-4659870d9753"
      },
      "source": [
        "! gdown --id 1u5lrzkLqhH5e9F_3fBdLd066z4h51j3z"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1u5lrzkLqhH5e9F_3fBdLd066z4h51j3z\n",
            "To: /content/combined_book_reviews.csv\n",
            "59.7MB [00:00, 128MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmORw4_8HPd1"
      },
      "source": [
        "\"\"\"\r\n",
        "import pandas as pd\r\n",
        "import gzip\r\n",
        "\r\n",
        "def parse(path):\r\n",
        "  g = gzip.open(path, 'rb')\r\n",
        "  for l in g:\r\n",
        "    yield eval(l)\r\n",
        "\r\n",
        "def getDF(path):\r\n",
        "  i = 0\r\n",
        "  df = {}\r\n",
        "  for d in parse(path):\r\n",
        "    df[i] = d\r\n",
        "    i += 1\r\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\r\n",
        "\r\n",
        "df = getDF('/content/reviews_Cell_Phones_and_Accessories_5.json.gz')\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjEgXoorEwoi"
      },
      "source": [
        "df = pd.read_csv('/content/combined_book_reviews.csv')\r\n",
        "df.rename(columns={'reviewText': 'reviews'}, inplace=True)\r\n",
        "df =df [['reviews']]\r\n",
        "df= df[df['reviews'].apply(lambda x: isinstance(x, str))]\r\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLR01OXjJhb0"
      },
      "source": [
        "# case text as lowercase, remove punctuation, remove extra whitespace in string and on both sides of string\r\n",
        "\r\n",
        "df['remove_lower_punct'] = df['reviews'].str.lower().str.replace(\"'\", '').str.replace('[^\\w\\s]', ' ').str.replace(\" \\d+\", \" \").str.replace(' +', ' ').str.replace('\\r','').str.replace('\\n','').str.strip()\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WREX1CP6Ly80",
        "outputId": "7f07e7bd-14f2-4c9f-ea09-80a9ff94fcc3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>remove_lower_punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book is a revelation. I cannot stop recom...</td>\n",
              "      <td>this book is a revelation i cannot stop recomm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I read this as an elderly American trying to u...</td>\n",
              "      <td>i read this as an elderly american trying to u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A lot of entrepreneurship books over the last ...</td>\n",
              "      <td>a lot of entrepreneurship books over the last ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loved FMD for years, I was excited to get this...</td>\n",
              "      <td>loved fmd for years i was excited to get this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All of these reviews on how Roth uses the F wo...</td>\n",
              "      <td>all of these reviews on how roth uses the f wo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews                                 remove_lower_punct\n",
              "0  This book is a revelation. I cannot stop recom...  this book is a revelation i cannot stop recomm...\n",
              "1  I read this as an elderly American trying to u...  i read this as an elderly american trying to u...\n",
              "2  A lot of entrepreneurship books over the last ...  a lot of entrepreneurship books over the last ...\n",
              "3  Loved FMD for years, I was excited to get this...  loved fmd for years i was excited to get this ...\n",
              "4  All of these reviews on how Roth uses the F wo...  all of these reviews on how roth uses the f wo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC4Bfhr0KOHE"
      },
      "source": [
        "# apply sentiment analysis\r\n",
        "analyser = SentimentIntensityAnalyzer()\r\n",
        "\r\n",
        "sentiment_score_list = []\r\n",
        "sentiment_label_list = []\r\n",
        "\r\n",
        "for i in df['remove_lower_punct'].values.tolist():\r\n",
        "    sentiment_score = analyser.polarity_scores(i)\r\n",
        "\r\n",
        "    if sentiment_score['compound'] >= 0.05:\r\n",
        "        sentiment_score_list.append(sentiment_score['compound'])\r\n",
        "        sentiment_label_list.append('Positive')\r\n",
        "    elif sentiment_score['compound'] > -0.05 and sentiment_score['compound'] < 0.05:\r\n",
        "        sentiment_score_list.append(sentiment_score['compound'])\r\n",
        "        sentiment_label_list.append('Neutral')\r\n",
        "    elif sentiment_score['compound'] <= -0.05:\r\n",
        "        sentiment_score_list.append(sentiment_score['compound'])\r\n",
        "        sentiment_label_list.append('Negative')\r\n",
        "    \r\n",
        "df['sentiment'] = sentiment_label_list\r\n",
        "df['sentiment score'] = sentiment_score_list\r\n",
        "\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iiUXd7B8LgKd",
        "outputId": "5ff6f1e8-021c-47ac-aecb-1f16f4e16bca"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>remove_lower_punct</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book is a revelation. I cannot stop recom...</td>\n",
              "      <td>this book is a revelation i cannot stop recomm...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I read this as an elderly American trying to u...</td>\n",
              "      <td>i read this as an elderly american trying to u...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.8525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A lot of entrepreneurship books over the last ...</td>\n",
              "      <td>a lot of entrepreneurship books over the last ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loved FMD for years, I was excited to get this...</td>\n",
              "      <td>loved fmd for years i was excited to get this ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>-0.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All of these reviews on how Roth uses the F wo...</td>\n",
              "      <td>all of these reviews on how roth uses the f wo...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  ... sentiment score\n",
              "0  This book is a revelation. I cannot stop recom...  ...          0.9915\n",
              "1  I read this as an elderly American trying to u...  ...          0.8525\n",
              "2  A lot of entrepreneurship books over the last ...  ...          0.9467\n",
              "3  Loved FMD for years, I was excited to get this...  ...         -0.2500\n",
              "4  All of these reviews on how Roth uses the F wo...  ...          0.9876\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm3H0N5SNwyZ",
        "outputId": "243340a4-a0a3-4506-ff5b-2e88c0ec47f1"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBwdAq0vKYbB"
      },
      "source": [
        "# tokenise string\r\n",
        "\r\n",
        "df['tokenise'] = df.apply(lambda row: nltk.word_tokenize(row[1]), axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1qJLcpUbNudS",
        "outputId": "ea24fffb-898a-4027-89a0-975785cc4eeb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>remove_lower_punct</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment score</th>\n",
              "      <th>tokenise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book is a revelation. I cannot stop recom...</td>\n",
              "      <td>this book is a revelation i cannot stop recomm...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9915</td>\n",
              "      <td>[this, book, is, a, revelation, i, can, not, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I read this as an elderly American trying to u...</td>\n",
              "      <td>i read this as an elderly american trying to u...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.8525</td>\n",
              "      <td>[i, read, this, as, an, elderly, american, try...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A lot of entrepreneurship books over the last ...</td>\n",
              "      <td>a lot of entrepreneurship books over the last ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9467</td>\n",
              "      <td>[a, lot, of, entrepreneurship, books, over, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loved FMD for years, I was excited to get this...</td>\n",
              "      <td>loved fmd for years i was excited to get this ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>[loved, fmd, for, years, i, was, excited, to, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All of these reviews on how Roth uses the F wo...</td>\n",
              "      <td>all of these reviews on how roth uses the f wo...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9876</td>\n",
              "      <td>[all, of, these, reviews, on, how, roth, uses,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  ...                                           tokenise\n",
              "0  This book is a revelation. I cannot stop recom...  ...  [this, book, is, a, revelation, i, can, not, s...\n",
              "1  I read this as an elderly American trying to u...  ...  [i, read, this, as, an, elderly, american, try...\n",
              "2  A lot of entrepreneurship books over the last ...  ...  [a, lot, of, entrepreneurship, books, over, th...\n",
              "3  Loved FMD for years, I was excited to get this...  ...  [loved, fmd, for, years, i, was, excited, to, ...\n",
              "4  All of these reviews on how Roth uses the F wo...  ...  [all, of, these, reviews, on, how, roth, uses,...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsWwansKOUj-",
        "outputId": "aef3e388-4c8d-49cc-ca4f-d823a7fa8bcc"
      },
      "source": [
        "\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "yEX-DhZRN1o7",
        "outputId": "710ba457-2741-4750-ad0c-7ebd447a9be8"
      },
      "source": [
        "# initiate stopwords from nltk\r\n",
        "\r\n",
        "stop_words = stopwords.words('english')\r\n",
        "\r\n",
        "# add additional missing terms\r\n",
        "\r\n",
        "stop_words.extend(stop_words_list) \r\n",
        "\r\n",
        "# remove stopwords\r\n",
        "\r\n",
        "df['remove_stopwords'] = df['tokenise'].apply(lambda x: [item for item in x if item not in stop_words])\r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>remove_lower_punct</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment score</th>\n",
              "      <th>tokenise</th>\n",
              "      <th>remove_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book is a revelation. I cannot stop recom...</td>\n",
              "      <td>this book is a revelation i cannot stop recomm...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9915</td>\n",
              "      <td>[this, book, is, a, revelation, i, can, not, s...</td>\n",
              "      <td>[book, revelation, recommending, book, peterse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I read this as an elderly American trying to u...</td>\n",
              "      <td>i read this as an elderly american trying to u...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.8525</td>\n",
              "      <td>[i, read, this, as, an, elderly, american, try...</td>\n",
              "      <td>[read, elderly, american, understand, millenni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A lot of entrepreneurship books over the last ...</td>\n",
              "      <td>a lot of entrepreneurship books over the last ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9467</td>\n",
              "      <td>[a, lot, of, entrepreneurship, books, over, th...</td>\n",
              "      <td>[lot, entrepreneurship, books, decade, felt, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loved FMD for years, I was excited to get this...</td>\n",
              "      <td>loved fmd for years i was excited to get this ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>[loved, fmd, for, years, i, was, excited, to, ...</td>\n",
              "      <td>[loved, fmd, years, excited, book, haylie, pom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All of these reviews on how Roth uses the F wo...</td>\n",
              "      <td>all of these reviews on how roth uses the f wo...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9876</td>\n",
              "      <td>[all, of, these, reviews, on, how, roth, uses,...</td>\n",
              "      <td>[reviews, roth, word, sexual, situations, slow...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  ...                                   remove_stopwords\n",
              "0  This book is a revelation. I cannot stop recom...  ...  [book, revelation, recommending, book, peterse...\n",
              "1  I read this as an elderly American trying to u...  ...  [read, elderly, american, understand, millenni...\n",
              "2  A lot of entrepreneurship books over the last ...  ...  [lot, entrepreneurship, books, decade, felt, a...\n",
              "3  Loved FMD for years, I was excited to get this...  ...  [loved, fmd, years, excited, book, haylie, pom...\n",
              "4  All of these reviews on how Roth uses the F wo...  ...  [reviews, roth, word, sexual, situations, slow...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VaYJaMrOxDF",
        "outputId": "3df7cb8e-602e-4876-9468-fc5f2f929f01"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "Y8nPKTvGOSHo",
        "outputId": "c110a9fc-9906-488f-d93e-1fed886ecb50"
      },
      "source": [
        "# initiate nltk lemmatiser\r\n",
        "\r\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "# lemmatise words\r\n",
        "\r\n",
        "df['lemmatise'] = df['remove_stopwords'].apply(lambda x: [wordnet_lemmatizer.lemmatize(y) for y in x]) \r\n",
        "\r\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>remove_lower_punct</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment score</th>\n",
              "      <th>tokenise</th>\n",
              "      <th>remove_stopwords</th>\n",
              "      <th>lemmatise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book is a revelation. I cannot stop recom...</td>\n",
              "      <td>this book is a revelation i cannot stop recomm...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9915</td>\n",
              "      <td>[this, book, is, a, revelation, i, can, not, s...</td>\n",
              "      <td>[book, revelation, recommending, book, peterse...</td>\n",
              "      <td>[book, revelation, recommending, book, peterse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I read this as an elderly American trying to u...</td>\n",
              "      <td>i read this as an elderly american trying to u...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.8525</td>\n",
              "      <td>[i, read, this, as, an, elderly, american, try...</td>\n",
              "      <td>[read, elderly, american, understand, millenni...</td>\n",
              "      <td>[read, elderly, american, understand, millenni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A lot of entrepreneurship books over the last ...</td>\n",
              "      <td>a lot of entrepreneurship books over the last ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9467</td>\n",
              "      <td>[a, lot, of, entrepreneurship, books, over, th...</td>\n",
              "      <td>[lot, entrepreneurship, books, decade, felt, a...</td>\n",
              "      <td>[lot, entrepreneurship, book, decade, felt, ai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loved FMD for years, I was excited to get this...</td>\n",
              "      <td>loved fmd for years i was excited to get this ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>[loved, fmd, for, years, i, was, excited, to, ...</td>\n",
              "      <td>[loved, fmd, years, excited, book, haylie, pom...</td>\n",
              "      <td>[loved, fmd, year, excited, book, haylie, pomr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All of these reviews on how Roth uses the F wo...</td>\n",
              "      <td>all of these reviews on how roth uses the f wo...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9876</td>\n",
              "      <td>[all, of, these, reviews, on, how, roth, uses,...</td>\n",
              "      <td>[reviews, roth, word, sexual, situations, slow...</td>\n",
              "      <td>[review, roth, word, sexual, situation, slow, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  ...                                          lemmatise\n",
              "0  This book is a revelation. I cannot stop recom...  ...  [book, revelation, recommending, book, peterse...\n",
              "1  I read this as an elderly American trying to u...  ...  [read, elderly, american, understand, millenni...\n",
              "2  A lot of entrepreneurship books over the last ...  ...  [lot, entrepreneurship, book, decade, felt, ai...\n",
              "3  Loved FMD for years, I was excited to get this...  ...  [loved, fmd, year, excited, book, haylie, pomr...\n",
              "4  All of these reviews on how Roth uses the F wo...  ...  [review, roth, word, sexual, situation, slow, ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3p4v-vaOuOL",
        "outputId": "1775d034-d9e5-4e66-ade6-a77c117cdc2c"
      },
      "source": [
        "# initialise the count vectorizer\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(analyzer = 'word', ngram_range = (2, 2))\r\n",
        "                            \r\n",
        "# join the processed data to be vectorised\r\n",
        "\r\n",
        "vectors = []\r\n",
        "\r\n",
        "for index, row in df.iterrows():\r\n",
        "    vectors.append(\", \".join(row['lemmatise']))\r\n",
        "\r\n",
        "vectorised = vectorizer.fit_transform(vectors)\r\n",
        "\r\n",
        "print(vectorised)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 178717)\t1\n",
            "  (0, 1379097)\t1\n",
            "  (0, 1337104)\t1\n",
            "  (0, 177551)\t1\n",
            "  (0, 1196074)\t1\n",
            "  (0, 514061)\t1\n",
            "  (0, 1766160)\t1\n",
            "  (0, 789131)\t1\n",
            "  (0, 874078)\t1\n",
            "  (0, 1052648)\t1\n",
            "  (0, 1642649)\t1\n",
            "  (0, 291658)\t1\n",
            "  (0, 1094441)\t1\n",
            "  (0, 776825)\t1\n",
            "  (0, 1052585)\t1\n",
            "  (0, 148354)\t1\n",
            "  (0, 1710073)\t1\n",
            "  (0, 501537)\t2\n",
            "  (0, 1685749)\t1\n",
            "  (0, 1453090)\t2\n",
            "  (0, 182828)\t1\n",
            "  (0, 1697390)\t1\n",
            "  (0, 182819)\t1\n",
            "  (0, 1164933)\t1\n",
            "  (0, 1052630)\t1\n",
            "  :\t:\n",
            "  (123187, 1418141)\t1\n",
            "  (123187, 526761)\t1\n",
            "  (123187, 123144)\t1\n",
            "  (123187, 697312)\t1\n",
            "  (123187, 46157)\t1\n",
            "  (123187, 573343)\t1\n",
            "  (123187, 1740)\t1\n",
            "  (123187, 1313885)\t1\n",
            "  (123188, 1379908)\t1\n",
            "  (123188, 1307849)\t1\n",
            "  (123188, 1050606)\t1\n",
            "  (123188, 178095)\t1\n",
            "  (123188, 176608)\t1\n",
            "  (123188, 1311762)\t1\n",
            "  (123188, 1284712)\t1\n",
            "  (123188, 724858)\t1\n",
            "  (123188, 178499)\t1\n",
            "  (123188, 45942)\t1\n",
            "  (123188, 1701655)\t1\n",
            "  (123188, 1021897)\t1\n",
            "  (123188, 1560108)\t1\n",
            "  (123188, 176434)\t1\n",
            "  (123188, 1105052)\t1\n",
            "  (123188, 1230290)\t1\n",
            "  (123188, 1350486)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oxL8qCpX_yQ",
        "outputId": "22bfb475-9e98-4cd7-fe86-52c8a76b6fbc"
      },
      "source": [
        "len(vectors), vectorised.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(123189, (123189, 1833434))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L9_89r-PHHN"
      },
      "source": [
        "## TOPIC MODELLING\r\n",
        "\r\n",
        "Topic modelling is an unsupervised machine learning approach used to distribute texts into groups which best characterise such documents. This concept can also be used to extract text aspects.\r\n",
        "\r\n",
        "Sklearn includes a version of the Latent Dirichlet Allocation (LDA) algorithm. For this concept, we want to extract five aspects. Once the parameters are set, we can fit the LDA to the vectorised version of the text.\r\n",
        "\r\n",
        "To make the output easier to read, we can append the relevance score produced for each topic to each review as a column and calculate the dominant topic by taking the topic with the highest relevance score.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYZBW_zNov9L"
      },
      "source": [
        "### df= df[['reviews', 'remove_lower_punct', 'sentiment', 'sentiment score', 'tokenise', 'remove_stopwords', 'lemmatise']]\r\n",
        "### df.head()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "JNjlqpYKO-Ok",
        "outputId": "01f669d4-eb21-4d86-9533-13e15784a89b"
      },
      "source": [
        "# initisalise LDA Model\r\n",
        "\r\n",
        "lda_model = LatentDirichletAllocation(n_components = 12, # number of topics\r\n",
        "                                  random_state = 10,          # random state\r\n",
        "                                  evaluate_every = -1,      # compute perplexity every n iters, default: Don't\r\n",
        "                                  n_jobs = -1,              # Use all available CPUs\r\n",
        "                                 )\r\n",
        "\r\n",
        "lda_output = lda_model.fit_transform(vectorised)\r\n",
        "\r\n",
        "# column names\r\n",
        "\r\n",
        "topic_names = [\"Topic\" + str(i) for i in range(1, lda_model.n_components + 1)]\r\n",
        "\r\n",
        "# make the pandas dataframe\r\n",
        "\r\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns = topic_names)\r\n",
        "\r\n",
        "# get dominant topic for each document\r\n",
        "\r\n",
        "dominant_topic = (np.argmax(df_document_topic.values, axis=1)+1)\r\n",
        "df_document_topic['Dominant_topic'] = dominant_topic\r\n",
        "\r\n",
        "# join to original dataframes\r\n",
        "\r\n",
        "df = pd.merge(df, df_document_topic, left_index = True, right_index = True, how = 'outer')\r\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>remove_lower_punct</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment score</th>\n",
              "      <th>tokenise</th>\n",
              "      <th>remove_stopwords</th>\n",
              "      <th>lemmatise</th>\n",
              "      <th>Topic1</th>\n",
              "      <th>Topic2</th>\n",
              "      <th>Topic3</th>\n",
              "      <th>Topic4</th>\n",
              "      <th>Topic5</th>\n",
              "      <th>Topic6</th>\n",
              "      <th>Topic7</th>\n",
              "      <th>Topic8</th>\n",
              "      <th>Topic9</th>\n",
              "      <th>Topic10</th>\n",
              "      <th>Topic11</th>\n",
              "      <th>Topic12</th>\n",
              "      <th>Dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book is a revelation. I cannot stop recom...</td>\n",
              "      <td>this book is a revelation i cannot stop recomm...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9915</td>\n",
              "      <td>[this, book, is, a, revelation, i, can, not, s...</td>\n",
              "      <td>[book, revelation, recommending, book, peterse...</td>\n",
              "      <td>[book, revelation, recommending, book, peterse...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I read this as an elderly American trying to u...</td>\n",
              "      <td>i read this as an elderly american trying to u...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.8525</td>\n",
              "      <td>[i, read, this, as, an, elderly, american, try...</td>\n",
              "      <td>[read, elderly, american, understand, millenni...</td>\n",
              "      <td>[read, elderly, american, understand, millenni...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A lot of entrepreneurship books over the last ...</td>\n",
              "      <td>a lot of entrepreneurship books over the last ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9467</td>\n",
              "      <td>[a, lot, of, entrepreneurship, books, over, th...</td>\n",
              "      <td>[lot, entrepreneurship, books, decade, felt, a...</td>\n",
              "      <td>[lot, entrepreneurship, book, decade, felt, ai...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loved FMD for years, I was excited to get this...</td>\n",
              "      <td>loved fmd for years i was excited to get this ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>[loved, fmd, for, years, i, was, excited, to, ...</td>\n",
              "      <td>[loved, fmd, years, excited, book, haylie, pom...</td>\n",
              "      <td>[loved, fmd, year, excited, book, haylie, pomr...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>All of these reviews on how Roth uses the F wo...</td>\n",
              "      <td>all of these reviews on how roth uses the f wo...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0.9876</td>\n",
              "      <td>[all, of, these, reviews, on, how, roth, uses,...</td>\n",
              "      <td>[reviews, roth, word, sexual, situations, slow...</td>\n",
              "      <td>[review, roth, word, sexual, situation, slow, ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  ... Dominant_topic\n",
              "0  This book is a revelation. I cannot stop recom...  ...              8\n",
              "1  I read this as an elderly American trying to u...  ...              8\n",
              "2  A lot of entrepreneurship books over the last ...  ...             11\n",
              "3  Loved FMD for years, I was excited to get this...  ...              8\n",
              "4  All of these reviews on how Roth uses the F wo...  ...              8\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMvL6OvLHR4A"
      },
      "source": [
        "df.to_csv('absa_df.csv', index=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2pePjKbYPfa",
        "outputId": "f073d02f-1b32-4003-cf89-676c607e3e8b"
      },
      "source": [
        "lda_output.shape, vectorised.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((123189, 12), (123189, 1833434))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adSF6rnQPyFj"
      },
      "source": [
        "Now we can see which topic (by its number) a review belongs to. But what keywords, in this case text aspects, has the LDA extracted from such reviews? We can view them by calling the vectoriser’s get_feature_names() and see their relevance score to that aspect using the LDA’s components_functions:\r\n",
        "\r\n",
        "We determine which aspect a keyword belongs to by taking its highest relevance score across the five aspects. Then, for each aspect, we can order our dataframe in descending order and select the keywords with the highest score.\r\n",
        "\r\n",
        "The five aspects are:\r\n",
        "\r\n",
        "    Battery charger\r\n",
        "    Battery pack\r\n",
        "    Car charger\r\n",
        "    Cell phone\r\n",
        "    Screen protector\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxGpuLNxZeQo",
        "outputId": "cb38598a-a4f0-4650-fee1-cbb5576f0625"
      },
      "source": [
        "lda_model.components_.shape, vectorised.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12, 1833434), (123189, 1833434))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMOJWwuZZ8hi",
        "outputId": "5ad5122e-db67-43d3-906a-2d6514802495"
      },
      "source": [
        "vectorizer.get_feature_names()[:5]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['006 v865', '03 nytimes', '03 real', '03 russia', '0440442508 book']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "isH_0xzBP4PY",
        "outputId": "e1367aeb-1de2-4086-eb60-2cf5867ead7f"
      },
      "source": [
        "# index names\r\n",
        "docnames = ['Doc' + str(i) for i in range(len(df))]\r\n",
        "\r\n",
        "# Make the pandas dataframe\r\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=docnames)\r\n",
        "\r\n",
        "# Get dominant topic for each document\r\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\r\n",
        "df_document_topic['dominant_topic'] = dominant_topic\r\n",
        "\r\n",
        "# Topic-Keyword Matrix\r\n",
        "df_topic_keywords = pd.DataFrame(lda_model.components_)\r\n",
        "\r\n",
        "# Assign Column and Index\r\n",
        "df_topic_keywords.columns = vectorizer.get_feature_names()\r\n",
        "df_topic_keywords.index = topic_names\r\n",
        "\r\n",
        "df_topic_no = pd.DataFrame(df_topic_keywords.idxmax())\r\n",
        "df_scores = pd.DataFrame(df_topic_keywords.max())\r\n",
        "\r\n",
        "tmp = pd.merge(df_topic_no, df_scores, left_index=True, right_index=True)\r\n",
        "tmp.columns = ['topic', 'relevance_score']\r\n",
        "\r\n",
        "display(tmp)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>relevance_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>006 v865</th>\n",
              "      <td>Topic10</td>\n",
              "      <td>1.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03 nytimes</th>\n",
              "      <td>Topic12</td>\n",
              "      <td>1.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03 real</th>\n",
              "      <td>Topic12</td>\n",
              "      <td>1.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03 russia</th>\n",
              "      <td>Topic11</td>\n",
              "      <td>1.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0440442508 book</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>1.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>𝗥𝗶𝘀𝗶𝗻𝗴 𝗗𝗮𝗿𝗸</th>\n",
              "      <td>Topic9</td>\n",
              "      <td>2.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>𝗮𝗻𝗱 𝘁𝗵𝗲</th>\n",
              "      <td>Topic9</td>\n",
              "      <td>2.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>𝗯𝗼𝗼𝗸 𝗳𝗿𝗶𝗲𝗻𝗱𝘀</th>\n",
              "      <td>Topic9</td>\n",
              "      <td>1.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>𝗳𝗿𝗶𝗲𝗻𝗱𝘀 reading</th>\n",
              "      <td>Topic9</td>\n",
              "      <td>1.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>𝘁𝗵𝗲 𝗥𝗶𝘀𝗶𝗻𝗴</th>\n",
              "      <td>Topic9</td>\n",
              "      <td>2.083333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1833434 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   topic  relevance_score\n",
              "006 v865         Topic10         1.083333\n",
              "03 nytimes       Topic12         1.083333\n",
              "03 real          Topic12         1.083333\n",
              "03 russia        Topic11         1.083333\n",
              "0440442508 book   Topic6         1.083333\n",
              "...                  ...              ...\n",
              "𝗥𝗶𝘀𝗶𝗻𝗴 𝗗𝗮𝗿𝗸       Topic9         2.083333\n",
              "𝗮𝗻𝗱 𝘁𝗵𝗲           Topic9         2.083333\n",
              "𝗯𝗼𝗼𝗸 𝗳𝗿𝗶𝗲𝗻𝗱𝘀      Topic9         1.083333\n",
              "𝗳𝗿𝗶𝗲𝗻𝗱𝘀 reading   Topic9         1.083333\n",
              "𝘁𝗵𝗲 𝗥𝗶𝘀𝗶𝗻𝗴        Topic9         2.083333\n",
              "\n",
              "[1833434 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "k3Eucuk7TUgE",
        "outputId": "da588707-8aeb-4a60-f12f-b3b8ee2381f9"
      },
      "source": [
        "all_topics = []\r\n",
        "\r\n",
        "for i in tmp['topic'].unique():    \r\n",
        "    tmp_1 = tmp.loc[tmp['topic'] == i].reset_index()\r\n",
        "    tmp_1 = tmp_1.sort_values('relevance_score', ascending=False).head(1)\r\n",
        "\r\n",
        "    #tmp_1['topic'] = tmp_1['topic'] + 1\r\n",
        "    \r\n",
        "    tmp_2 = []\r\n",
        "    tmp_2.append(tmp_1['topic'].unique()[0])\r\n",
        "    tmp_2.append(list(tmp_1['index'].unique()))\r\n",
        "    all_topics.append(tmp_2)\r\n",
        "\r\n",
        "all_topics = pd.DataFrame(all_topics, columns=['Dominant_topic', 'topic_name'])\r\n",
        "display(all_topics)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant_topic</th>\n",
              "      <th>topic_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Topic10</td>\n",
              "      <td>[book book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Topic12</td>\n",
              "      <td>[book written]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Topic11</td>\n",
              "      <td>[read book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Topic6</td>\n",
              "      <td>[excellent book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Topic5</td>\n",
              "      <td>[favorite book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Topic2</td>\n",
              "      <td>[polar express]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Topic8</td>\n",
              "      <td>[ten finger]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Topic7</td>\n",
              "      <td>[good book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Topic4</td>\n",
              "      <td>[main character]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Topic3</td>\n",
              "      <td>[loved book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Topic9</td>\n",
              "      <td>[book read]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Topic1</td>\n",
              "      <td>[good read]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dominant_topic        topic_name\n",
              "0         Topic10       [book book]\n",
              "1         Topic12    [book written]\n",
              "2         Topic11       [read book]\n",
              "3          Topic6  [excellent book]\n",
              "4          Topic5   [favorite book]\n",
              "5          Topic2   [polar express]\n",
              "6          Topic8      [ten finger]\n",
              "7          Topic7       [good book]\n",
              "8          Topic4  [main character]\n",
              "9          Topic3      [loved book]\n",
              "10         Topic9       [book read]\n",
              "11         Topic1       [good read]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjLCP5dSihYE"
      },
      "source": [
        "for idx, row in all_topics.iterrows():\r\n",
        "  m= int(row['Dominant_topic'].replace('Topic',''))\r\n",
        "  row['Dominant_topic']=m"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "9l14bg8FP06a",
        "outputId": "569c5074-c395-46aa-ad53-c389e20d1387"
      },
      "source": [
        "all_topics"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant_topic</th>\n",
              "      <th>topic_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>[book book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>[book written]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>[read book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>[excellent book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[favorite book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>[polar express]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>[ten finger]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>[good book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>[main character]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>[loved book]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>[book read]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>[good read]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dominant_topic        topic_name\n",
              "0              10       [book book]\n",
              "1              12    [book written]\n",
              "2              11       [read book]\n",
              "3               6  [excellent book]\n",
              "4               5   [favorite book]\n",
              "5               2   [polar express]\n",
              "6               8      [ten finger]\n",
              "7               7       [good book]\n",
              "8               4  [main character]\n",
              "9               3      [loved book]\n",
              "10              9       [book read]\n",
              "11              1       [good read]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dol004JNibZ"
      },
      "source": [
        "## SENTIMENT ANALYSIS\r\n",
        "\r\n",
        "Various techniques and methodologies have been developed to address automatically identifying the sentiment expressed in the text. In this post, I’ll use VADER, a Python sentiment analysis library, to classify whether the reviews are positive, negative, or neutral.\r\n",
        "\r\n",
        "A very simple approach to sentiment analysis is by using a list of words which have been labelled according to their semantic orientation. For example, we can assume that the word “good” has a positive valence, whereas the word “bad” has a negative one. VADER uses this technique and provides a percentage score which represents the proportion of lyrics which fall in each sentiment category. It also provides a compound score which is computed by summing the valence scores of each word and then normalising the scores to be between -1 (most extreme negative) and +1 (most extreme positive).\r\n",
        "\r\n",
        "What’s nice about VADER is the fact that we don’t have to pre-process the text in any way. We can feed the raw product reviews into VADER’s sentiment function and retrieve the compound scores for each.\r\n",
        "\r\n",
        "First, we’ll import the SentimentIntensityAnalyzer function from VADER’s Python library. I’ll initialise the sentiment analyser from VADER, and then iterate over the reviews from the dataframe. I’ll then calculate whether the compound sentiment score is above or beneath the thresholds so that we can assign them with the positive, negative, or neutral label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ4_P4UzTl-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "46fe855b-5364-469d-d2fd-688a645719f7"
      },
      "source": [
        "results = df.groupby(['Dominant_topic', 'sentiment']).count().reset_index()\r\n",
        "\r\n",
        "results = results.merge(all_topics, on='Dominant_topic')\r\n",
        "results['topic_name'] = results['topic_name'].apply(', '.join)\r\n",
        "\r\n",
        "graph_results = results[['topic_name', 'sentiment', 'sentiment score']]\r\n",
        "graph_results = graph_results.pivot(index='topic_name', columns='sentiment', values='sentiment score').reset_index()\r\n",
        "\r\n",
        "graph_results.set_index('topic_name', inplace=True)\r\n",
        "\r\n",
        "display(graph_results)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>sentiment</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Positive</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>book book</th>\n",
              "      <td>1118</td>\n",
              "      <td>525</td>\n",
              "      <td>8441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>book read</th>\n",
              "      <td>1073</td>\n",
              "      <td>565</td>\n",
              "      <td>8899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>book written</th>\n",
              "      <td>1042</td>\n",
              "      <td>546</td>\n",
              "      <td>8139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>excellent book</th>\n",
              "      <td>972</td>\n",
              "      <td>466</td>\n",
              "      <td>6905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>favorite book</th>\n",
              "      <td>1017</td>\n",
              "      <td>605</td>\n",
              "      <td>8845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>good book</th>\n",
              "      <td>1067</td>\n",
              "      <td>616</td>\n",
              "      <td>10332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>good read</th>\n",
              "      <td>1406</td>\n",
              "      <td>2173</td>\n",
              "      <td>13330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loved book</th>\n",
              "      <td>953</td>\n",
              "      <td>527</td>\n",
              "      <td>6916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>main character</th>\n",
              "      <td>1065</td>\n",
              "      <td>539</td>\n",
              "      <td>7414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>polar express</th>\n",
              "      <td>1083</td>\n",
              "      <td>538</td>\n",
              "      <td>7884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>read book</th>\n",
              "      <td>1043</td>\n",
              "      <td>637</td>\n",
              "      <td>8011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ten finger</th>\n",
              "      <td>1025</td>\n",
              "      <td>553</td>\n",
              "      <td>6919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "sentiment       Negative  Neutral  Positive\n",
              "topic_name                                 \n",
              "book book           1118      525      8441\n",
              "book read           1073      565      8899\n",
              "book written        1042      546      8139\n",
              "excellent book       972      466      6905\n",
              "favorite book       1017      605      8845\n",
              "good book           1067      616     10332\n",
              "good read           1406     2173     13330\n",
              "loved book           953      527      6916\n",
              "main character      1065      539      7414\n",
              "polar express       1083      538      7884\n",
              "read book           1043      637      8011\n",
              "ten finger          1025      553      6919"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "YL618rQ3ROuc",
        "outputId": "16e75099-cfca-42f6-a031-9fcb12c7d4d9"
      },
      "source": [
        "fig = graph_results.plot.bar(rot=90, figsize=(10,10))\r\n",
        "fig.figure.savefig('sentiment_analysis_books_12_aspect.png', bbox_inches='tight')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXC6H7eFRhjt"
      },
      "source": [
        "## INSIGHTS FROM THE RESULTS\r\n",
        "\r\n",
        "Once we’ve retrieved the compound scores for each review, we can plot and count the number of positive, negative, and neutral reviews for each of the five aspects.\r\n",
        "\r\n",
        "This chart reports that the majority of the reviews for each aspect are positive. In particular, with more than 83,000 reviews, the screen protector received 49,572 positive ones. For a business, having more than 50% of your reviews expressing a positive sentiment is a good indication that your customers are satisfied with the product.\r\n",
        "\r\n",
        "What other potential insights can we gather? Let’s dive deeper into what the customers are saying. For this concept, we’ll use the reviews for the screen protector.\r\n",
        "\r\n",
        "One of the main features used to support Sentiment Analysis include individual sentiment words (e.g. good, bad) which explicitly convey a subjective bias. Sentiment words are available from specialised dictionaries, where they have been mapped to their sentiment.\r\n",
        "\r\n",
        "These words are often adjectives (e.g. good, bad), adverbs (e.g. cheerfully, weirdly), nouns (e.g. blessing, rubbish), and verbs (e.g. love, hate). Sentiment may also be expressed by using comparative words (e.g. better, worse). To identify those adjectives, adverbs, nouns, and verbs in text, we can apply Part of Speech (POS) tagging. POS tagging is the process of marking up a word in a text as corresponding to a particular part of speech (noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, numeral, article, or determiner), based on both its definition and its context.\r\n",
        "\r\n",
        "Here, we use the NLTK POS tagger to identify the POS tags. As we’ve got quite a large dataset, we want to automatically narrow down the sentiment words as much as possible. In this case, we’re able to identify English and correctly spelt words and map them to SentiWordNet, a lexical resource for opinion mining. SentiWordNet assigns words three sentiment scores: positivity, negativity, and objectivity.\r\n",
        "\r\n",
        "Objectivity can be defined as not being influenced by personal feelings or opinions in considering and representing facts. Subjectivity is therefore the contrast of objectivity. In terms of scoring, we want to identify words with low objectivity score. But not all subjective words are sentiment words.\r\n",
        "\r\n",
        "To capture sentiment words from subjective ones, we use WordNet-Affect, another lexical resource which represents affective concepts correlated with affective words in a hierarchical structure. Once we’ve checked whether the subjective words are in WordNet-Affect, we can be quite confident that these are sentiment words. Based on their SentiWordNet positive and negative score, we can also split them up into separate collections and count how many times they appear across the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POl1iEKIRxyG",
        "outputId": "fb88ceb6-592b-4c96-f6a8-cee1677a2336"
      },
      "source": [
        "### nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjB5rcFPRQmn",
        "outputId": "3289a863-c07c-4160-b762-25e6b900ac11"
      },
      "source": [
        "\"\"\"\r\n",
        "from nltk.corpus import wordnet\r\n",
        "\r\n",
        "def get_wordnet_pos(treebank_tag):\r\n",
        "\r\n",
        "    if treebank_tag.startswith('J'):\r\n",
        "        return wordnet.ADJ\r\n",
        "    elif treebank_tag.startswith('V'):\r\n",
        "        return wordnet.VERB\r\n",
        "    elif treebank_tag.startswith('N'):\r\n",
        "        return wordnet.NOUN\r\n",
        "    elif treebank_tag.startswith('R'):\r\n",
        "        return wordnet.ADV\r\n",
        "    else:\r\n",
        "        pass\r\n",
        "\r\n",
        "positive_words = []\r\n",
        "negative_words = []\r\n",
        "\r\n",
        "for i in df['Dominant_topic'].unique():\r\n",
        "    if i == 1:\r\n",
        "        tmp_1 = df.loc[df['Dominant_topic'] == i]\r\n",
        "                \r\n",
        "        for j in tmp_1['tokenise'].values.tolist():\r\n",
        "            for p in nltk.pos_tag(j):\r\n",
        "                get_pos_tag = get_wordnet_pos(p[1])\r\n",
        "                if type(get_pos_tag) == str:\r\n",
        "                    try:        \r\n",
        "                        synset = swn.senti_synset(p[0] + '.' + get_pos_tag +'.01')\r\n",
        "\r\n",
        "                        if synset.obj_score() <= 0.49:\r\n",
        "                            if synset.pos_score() > synset.neg_score() and p[0] in wn_affect:\r\n",
        "                                    positive_words.append(p[0])\r\n",
        "                            elif synset.neg_score() > synset.pos_score() and p[0] in wn_affect:\r\n",
        "                                    negative_words.append(p[0])      \r\n",
        "                    except:\r\n",
        "                        pass\r\n",
        "print(positive_words,'\\n')\r\n",
        "print(negative_words, '\\n')\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[] \n",
            "\n",
            "[] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yrNS2VQRvcX"
      },
      "source": [
        "\"\"\"\r\n",
        "unique_positive_words = list(set(positive_words))\r\n",
        "unique_negative_words = list(set(negative_words))\r\n",
        "\r\n",
        "count_positive_words = []\r\n",
        "count_negative_words = []\r\n",
        "\r\n",
        "for i in unique_positive_words:\r\n",
        "    counter = [i, positive_words.count(i)]\r\n",
        "    count_positive_words.append(counter)\r\n",
        "\r\n",
        "for i in unique_negative_words:\r\n",
        "    counter = [i, negative_words.count(i)]\r\n",
        "    count_negative_words.append(counter)    \r\n",
        "    \r\n",
        "positive_words = pd.DataFrame(count_positive_words, columns = ['word', 'score'])\r\n",
        "negative_words = pd.DataFrame(count_negative_words, columns = ['word', 'score'])\r\n",
        "\r\n",
        "positive_words.sort_values('score', ascending=False, inplace = True)\r\n",
        "negative_words.sort_values('score', ascending=False, inplace = True)\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "L--PlZEySJ_v",
        "outputId": "4421d84d-02a0-4604-f029-b3632870c18f"
      },
      "source": [
        "\"\"\"\r\n",
        "word_dict = {}\r\n",
        "for k, v in positive_words.values:\r\n",
        "    word_dict[k] = v\r\n",
        "\r\n",
        "wordcloud = WordCloud()\r\n",
        "wordcloud.generate_from_frequencies(frequencies=word_dict)\r\n",
        "plt.figure(figsize=(20,10))\r\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\r\n",
        "plt.axis(\"off\")\r\n",
        "plt.savefig('positive_words.png')\r\n",
        "plt.show()\r\n",
        "\"\"\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nword_dict = {}\\nfor k, v in positive_words.values:\\n    word_dict[k] = v\\n\\nwordcloud = WordCloud()\\nwordcloud.generate_from_frequencies(frequencies=word_dict)\\nplt.figure(figsize=(20,10))\\nplt.imshow(wordcloud, interpolation=\"bilinear\")\\nplt.axis(\"off\")\\nplt.savefig(\\'positive_words.png\\')\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysmQT7rgSaqe"
      },
      "source": [
        "\"\"\"\r\n",
        "word_dict = {}\r\n",
        "for k, v in negative_words.values:\r\n",
        "    word_dict[k] = v\r\n",
        "    \r\n",
        "wordcloud.generate_from_frequencies(frequencies=word_dict)\r\n",
        "plt.figure(figsize=(20,10))\r\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\r\n",
        "plt.axis(\"off\")\r\n",
        "plt.savefig('negative_words.png')\r\n",
        "plt.show()\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}